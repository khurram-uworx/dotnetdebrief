{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .NET üíñ ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .NET Runtime is matured\n",
    "- .NET has decent interop story\n",
    "- C# is cool\n",
    "- Types and Numerics\n",
    "- ML.NET\n",
    "- Microsoft & Azure\n",
    "- https://rubikscode.net/2021/10/25/using-huggingface-transformers-with-ml-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ ML.NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://dot.net/ml\n",
    "- https://github.com/dotnet/machinelearning\n",
    "    https://github.com/dotnet/machinelearning-samples\n",
    "- https://www.nuget.org/packages/Microsoft.ML\n",
    "\n",
    ".NET Break Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Microsoft.ML\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ML.NET is __build__, __train__, and __deploy__ machine learning models library\n",
    "- It doesnt come with pretrained models but we can use models through ONNX support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data__  ML.NET uses IDataView as the primary data structure for datasets\n",
    "- We can load data from various sources (e.g., CSV, databases, in-memory collections) using mlContext.Data.LoadFrom... methods\n",
    "\n",
    "__Transforms__ Data transformations are used to preprocess and prepare data for training\n",
    "- Feature engineering: Normalization, encoding categorical variables, text featurization, etc\n",
    "- Data cleaning: Handling missing values, filtering rows, etc\n",
    "- Column operations: Concatenating, renaming, or dropping columns\n",
    "\n",
    "__Model Training__ ML.NET supports various machine learning tasks:\n",
    "    - Classification: Binary and multiclass\n",
    "    - Regression: Predicting continuous values\n",
    "    - Clustering: Grouping similar data points\n",
    "    - Anomaly Detection: Identifying outliers\n",
    "    - Recommendation: Building recommendation systems\n",
    "- We can evaluate model, save and load and can use / make predictions\n",
    "\n",
    "__Advanced Features__\n",
    "- Model Explainability: Use Explainability methods to understand feature importance\n",
    "- Cross-Validation: Evaluate model performance using cross-validation\n",
    "- Time Series: Use specialized libraries for time-series forecasting\n",
    "- ONNX Support: Export/import models in the ONNX format for interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://devblogs.microsoft.com/dotnet/announcing-ml-net-2-0\n",
    "- https://devblogs.microsoft.com/dotnet/announcing-ml-net-3-0\n",
    "- https://github.com/dotnet/machinelearning/blob/main/docs/release-notes/4.0/release-4.0.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __\"Bag of Words\" (BoW)__ model is a way to represent text data in a numerical format that machine learning algorithms can understand. It's called a \"bag\" because it ignores the order of words and only focuses on the presence and frequency of words\n",
    "\n",
    "- Tokenization: Split the text into individual words (or tokens)\n",
    "- Counting Words: How many times each word appears in the text. This is where the \"Bag of Words\" comes into play. It creates a list of all unique words in your dataset and counts how often each word appears in each document (or text entry)\n",
    "- Vector Representation: Converts these counts into a numerical vector. Each position in the vector corresponds to a specific word, and the value at that position represents how many times that word appeared in the text\n",
    "- N-grams: Sequences of n words. For example, a 2-gram (bigram) would consider pairs of words like \"I love\", \"love programming\", etc. If you specify n-grams in ProduceWordBags, it will also count these sequences, not just individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.ML;\n",
    "using Microsoft.ML.Data;\n",
    "using System.Linq;\n",
    "\n",
    "class TransformedData\n",
    "{\n",
    "    public float[] BagOfWords { get; set; }\n",
    "}\n",
    "\n",
    "var mlContext = new MLContext();\n",
    "\n",
    "var data = new[]\n",
    "{\n",
    "    new { Text = \"I love programming in C#\" },\n",
    "    new { Text = \".NET is the best runtime\" },\n",
    "    //new { Text = \"I am liking machine learning\" } // Uncomment this line to see the effect of adding more data üëà\n",
    "};\n",
    "\n",
    "// Loading data into IDataView\n",
    "var dataView = mlContext.Data.LoadFromEnumerable(data);\n",
    "\n",
    "// Pipeline for Bag of Words\n",
    "var pipeline = mlContext.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"Text\")\n",
    "    .Append(mlContext.Transforms.Text.ProduceWordBags(\"BagOfWords\", \"Tokens\")); // Vector to n-grams count\n",
    "\n",
    "// Fit and transform data\n",
    "var transformer = pipeline.Fit(dataView);\n",
    "var transformedData = transformer.Transform(dataView);\n",
    "var embeddings = mlContext.Data.CreateEnumerable<TransformedData>(transformedData, reuseRowObject: false);\n",
    "\n",
    "foreach (var embedding in embeddings)\n",
    "    Console.WriteLine(string.Join(\", \", embedding.BagOfWords));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The length of the vector corresponds to the total number of unique words (or n-grams) in the vocabulary created from your dataset\n",
    "- Each position in the vector represents a specific word or n-gram. For example:\n",
    "    - Position 0 might correspond to \"I\"\n",
    "    - Position 1 might correspond to \"love\"\n",
    "    - Position 9 might correspond to \".NET\"\n",
    "    - And so on\n",
    "\n",
    "While creating Bag of Words; we can have an approach where we count appearance of word instead of just presence; doing so our vector will have other than 0, 1 values above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/vector-similarity.png>\n",
    "\n",
    "- https://chatgpt.com/share/67332e70-3228-800b-828c-935003396ed4 Dot Product, Cosine and Euclidean Distances\n",
    "- https://qdrant.tech/blog/what-is-vector-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var query = \"I love programming in Java\";\n",
    "var queryData = new[] { new { Text = query } };\n",
    "var queryDataView = mlContext.Data.LoadFromEnumerable(queryData);\n",
    "var queryTransformedData = transformer.Transform(queryDataView);\n",
    "var queryEmbedding = mlContext.Data.CreateEnumerable<TransformedData>(queryTransformedData, reuseRowObject: false);\n",
    "\n",
    "foreach (var embedding in queryEmbedding)\n",
    "    Console.WriteLine(string.Join(\", \", embedding.BagOfWords));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "float CosineSimilarity(float[] vectorA, float[] vectorB)\n",
    "{\n",
    "    float dotProduct = 0.0f;\n",
    "    float magnitudeA = 0.0f;\n",
    "    float magnitudeB = 0.0f;\n",
    "\n",
    "    for (int i = 0; i < vectorA.Length; i++) // We can use Vectors / Tensors for better performance\n",
    "    {\n",
    "        dotProduct += vectorA[i] * vectorB[i];\n",
    "        magnitudeA += vectorA[i] * vectorA[i];\n",
    "        magnitudeB += vectorB[i] * vectorB[i];\n",
    "    }\n",
    "\n",
    "    magnitudeA = (float)Math.Sqrt(magnitudeA);\n",
    "    magnitudeB = (float)Math.Sqrt(magnitudeB);\n",
    "\n",
    "    if (magnitudeA == 0 || magnitudeB == 0)\n",
    "        return 0;\n",
    "\n",
    "    return dotProduct / (magnitudeA * magnitudeB);\n",
    "}\n",
    "\n",
    "var closestEmbedding = data.Zip(embeddings, (d, e) => new { d, e })\n",
    "    .Select(x => new\n",
    "    {\n",
    "        Text = x.d.Text,\n",
    "        Similarity = CosineSimilarity(queryEmbedding.First().BagOfWords, x.e.BagOfWords)\n",
    "    })\n",
    "    .OrderByDescending(x => x.Similarity);\n",
    "\n",
    "foreach(var embedding in closestEmbedding)\n",
    "    Console.WriteLine($\"{embedding.Text}\\tSimilarity:\\t{embedding.Similarity}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Features__ refer to the individual measurable properties or characteristics of the data that are used as input to a machine learning model. Features are the variables (or columns) in our dataset that the model uses to make predictions or decisions. They represent the information that the model will learn from to make accurate predictions\n",
    "- __One Hot Encoding__ can be used to convert the categorical feature into a numerical representation. This is a common technique to handle categorical data in machine learning. The result is a dense vector\n",
    "- __Concatenation of Feature__ is when we concatenating all the features (including the one-hot encoded ones) into a single feature vector; we use Concatenate transform that creates a dense vector where all the features are combined into one array\n",
    "- __Feature Engineering__ is the process of selecting, transforming, and creating features (e.g., one-hot encoding, normalization, creating new features). Good feature engineering can significantly improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regression using ML.NET__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers\n",
    "    - https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.trainers.lbfgspoissonregressiontrainer\n",
    "        - https://en.wikipedia.org/wiki/Poisson_regression\n",
    "\n",
    "<img src=images/poisson-regression.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.ML;\n",
    "using Microsoft.ML.Data;\n",
    "using System.Collections.Generic;\n",
    "\n",
    "class HousingData\n",
    "{\n",
    "    [LoadColumn(0)] public float NumberOfRooms { get; set; }\n",
    "    [LoadColumn(1)] public float SquareFootage { get; set; }\n",
    "    [LoadColumn(2)] public string Location { get; set; }\n",
    "    [LoadColumn(3)] public float AgeOfHouse { get; set; }\n",
    "    [LoadColumn(4)] public float Price { get; set; }\n",
    "}\n",
    "class HousingPrediction\n",
    "{\n",
    "    [ColumnName(\"Score\")]\n",
    "    public float Price { get; set; }\n",
    "}\n",
    "\n",
    "var housingData = new List<HousingData>\n",
    "{\n",
    "    new HousingData { NumberOfRooms = 3, SquareFootage = 1500, Location = \"Urban\", AgeOfHouse = 10, Price = 300000 },\n",
    "    new HousingData { NumberOfRooms = 4, SquareFootage = 2000, Location = \"Suburban\", AgeOfHouse = 5, Price = 400000 },\n",
    "    new HousingData { NumberOfRooms = 2, SquareFootage = 1000, Location = \"Rural\", AgeOfHouse = 20, Price = 200000 }\n",
    "};\n",
    "\n",
    "var mlContext = new MLContext();\n",
    "var dataView = mlContext.Data.LoadFromEnumerable(housingData);\n",
    "var pipeline = mlContext.Transforms\n",
    "    .Categorical.OneHotEncoding(\"LocationEncoded\", \"Location\") // Encode categorical feature\n",
    "    .Append(mlContext.Transforms.Concatenate(\"Features\",\n",
    "        nameof(HousingData.NumberOfRooms), nameof(HousingData.SquareFootage),\n",
    "        \"LocationEncoded\",\n",
    "        nameof(HousingData.AgeOfHouse))) // Combine features into a dense vector\n",
    "    .Append(mlContext.Regression.Trainers.LbfgsPoissonRegression(labelColumnName: nameof(HousingData.Price))); // Train a regression model\n",
    "\n",
    "var model = pipeline.Fit(dataView);\n",
    "var predictionEngine = mlContext.Model.CreatePredictionEngine<HousingData, HousingPrediction>(model);\n",
    "\n",
    "var sampleHouse = new HousingData\n",
    "{\n",
    "    NumberOfRooms = 3,\n",
    "    SquareFootage = 1600,\n",
    "    Location = \"Urban\",\n",
    "    AgeOfHouse = 8\n",
    "};\n",
    "var prediction = predictionEngine.Predict(sampleHouse);\n",
    "\n",
    "Console.WriteLine($\"Predicted Price: {prediction.Price}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Accord.Net üóÉÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://accord-framework.net\n",
    "- https://github.com/accord-net/framework Archived in 2020\n",
    "- https://www.nuget.org/packages/Accord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TF-IDF__ Term Frequency-Inverse Document Frequency, is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus), Use cases:\n",
    "- Search Engines: To rank documents based on their relevance to a query\n",
    "- Text Classification: To identify important features (words) for machine learning models\n",
    "- Information Retrieval: To find the most relevant documents for a given search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Accord.Math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Accord.Math;\n",
    "\n",
    "class Tfidf\n",
    "{\n",
    "    string[] vocabulary;\n",
    "    double[] idf;\n",
    "\n",
    "    string[] documents;\n",
    "    public int VocabularyLength => vocabulary.Length;\n",
    "\n",
    "    public Tfidf(string[] documents)\n",
    "    {\n",
    "        var tokenizedDocs = documents.Select(d => d.Split(' ')).ToArray();\n",
    "        vocabulary = tokenizedDocs.SelectMany(x => x).Distinct().ToArray();\n",
    "        idf = new double[vocabulary.Length];\n",
    "\n",
    "        for (int i = 0; i < vocabulary.Length; i++)\n",
    "        {\n",
    "            int docCount = tokenizedDocs.Count(d => d.Contains(vocabulary[i]));\n",
    "            //idf[i] = Math.Log((double)documents.Length / (docCount + 1)); // to avoid dividing by zero\n",
    "            idf[i] = Math.Log((double)(documents.Length + 1) / (docCount + 1)); // Laplace smoothing\n",
    "        }\n",
    "\n",
    "        this.documents = documents;\n",
    "    }\n",
    "\n",
    "    public Sparse<double>[] Transform()\n",
    "    {\n",
    "        var sparseVectors = new Sparse<double>[this.documents.Length];\n",
    "\n",
    "        for (int i = 0; i < this.documents.Length; i++)\n",
    "        {\n",
    "            var tokens = this.documents[i].Split(' ');\n",
    "            var indices = new List<int>();\n",
    "            var values = new List<double>();\n",
    "\n",
    "            for (int j = 0; j < vocabulary.Length; j++)\n",
    "            {\n",
    "                int count = tokens.Count(t => t == vocabulary[j]);\n",
    "                if (count > 0)\n",
    "                {\n",
    "                    indices.Add(j);\n",
    "                    values.Add(count * idf[j]);\n",
    "                }\n",
    "            }\n",
    "\n",
    "            sparseVectors[i] = new Sparse<double>(indices.ToArray(), values.ToArray());\n",
    "        }\n",
    "\n",
    "        return sparseVectors;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string[] documents = {\n",
    "    \"I love programming in C#\",\n",
    "    \"C# is a great language\",\n",
    "    \"I hate bugs in my code\",\n",
    "    \"Debugging is essential in programming\"\n",
    "};\n",
    "\n",
    "var tfidf = new Tfidf(documents);\n",
    "var vectors = tfidf.Transform();\n",
    "\n",
    "for (int i = 0; i < vectors.Length; i++)\n",
    "    Console.WriteLine($\"Document {i + 1}:\\n\\t{vectors[i]}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Accord.Math.Distances;\n",
    "\n",
    "var cosine = new Cosine();\n",
    "double similarity = cosine.Similarity(vectors[0].ToDense(), vectors[1].ToDense());\n",
    "Console.WriteLine($\"Cosine Similarity: {similarity}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: Accord.MachineLearning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Accord.MachineLearning;\n",
    "\n",
    "double[][] denseVectors = vectors\n",
    "    .Select(v => v.ToDense(tfidf.VocabularyLength)) // Convert sparse to dense\n",
    "    .ToArray();\n",
    "\n",
    "denseVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "// \"I love programming in C#\",\n",
    "// \"C# is a great language\",\n",
    "// \"I hate bugs in my code\",\n",
    "// \"Debugging is essential in programming\"\n",
    "\n",
    "var kmeans = new KMeans(k: 2); // 2 clusters\n",
    "var clusters = kmeans.Learn(denseVectors);\n",
    "int[] labels = clusters.Decide(denseVectors);\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build upon using Accord.Net (and other machine learning libraries)\n",
    "\n",
    "- Dimensionality Reduction\n",
    "    - Principal Component Analysis (PCA)\n",
    "- Classification\n",
    "    - Support Vector Machines\n",
    "- Topic Modeling\n",
    "    - Latent Dirichlet Allocation; to discovers topics being in documents\n",
    "- Anamoly Detection\n",
    "    - One class SVM (Support Vector Machine)\n",
    "- Search & Retreival\n",
    "- Recommentation System\n",
    "    - Content-Based Filtering (TF-IDF)\n",
    "- Text Summarization\n",
    "- Feature Selection\n",
    "    - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß∞ Math.NET üóÉÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://mathdotnet.com\n",
    "    - https://numerics.mathdotnet.com\n",
    "    - https://github.com/mathnet/mathnet-numerics\n",
    "    - https://www.nuget.org/packages/MathNet.Numerics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can bring in more specialized numerical algorithms with this library\n",
    "- Math.NET offers more optimized high-performance sparse linear algebra; for very large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Restart Kernel__\n",
    "\n",
    "These libraries have their own Vector implementations and that's the problem in mixing and matching such libraries and their namespaces\n",
    "- How System.Numerics is solving this issue for future libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: MathNet.Numerics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using MathNet.Numerics.LinearAlgebra;\n",
    "\n",
    "double CalculateCosineSimilarity(Vector<double> vector1, Vector<double> vector2)\n",
    "{\n",
    "    double dotProduct = vector1.DotProduct(vector2);\n",
    "\n",
    "    double magnitude1 = vector1.L2Norm();\n",
    "    double magnitude2 = vector2.L2Norm();\n",
    "\n",
    "    double cosineSimilarity = dotProduct / (magnitude1 * magnitude2);\n",
    "    return cosineSimilarity;\n",
    "}\n",
    "\n",
    "var user1 = Vector<double>.Build.Dense(new double[] { 5, 4, 3, 0, 2 }); // User 1's ratings\n",
    "var user2 = Vector<double>.Build.Dense(new double[] { 1, 5, 4, 0, 3 }); // User 2's ratings\n",
    "double cosineSimilarity = CalculateCosineSimilarity(user1, user2);\n",
    "\n",
    "if (cosineSimilarity > 0.8)\n",
    "    Console.WriteLine(\"The users have very similar tastes!\");\n",
    "else if (cosineSimilarity > 0.5)\n",
    "    Console.WriteLine(\"The users have somewhat similar tastes.\");\n",
    "else\n",
    "    Console.WriteLine(\"The users have different tastes.\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [],
      "languageName": "python",
      "name": "pythonkernel"
     },
     {
      "aliases": [],
      "languageName": "R",
      "name": "Rkernel"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
