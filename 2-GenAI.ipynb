{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/dotnet/interactive/blob/HEAD/docs/jupyter-in-polyglot-notebooks.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!connect jupyter --kernel-name pythonkernel --kernel-spec python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun /w Languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/the-curly-languages.jpg height=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "javascript"
    },
    "polyglot_notebook": {
     "kernelName": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "//console.log(\"foo\" + + \"bar\");\n",
    "console.log([1, 2, 3] + [4, 5, 6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "print([1, 2, 3] + [4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using static System.Console;\n",
    "\n",
    "List<int> l = [1, 2, 3];\n",
    "WriteLine(string.Join(\", \", l.Concat([4, 5, 6])));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "fsharp"
    },
    "polyglot_notebook": {
     "kernelName": "fsharp"
    }
   },
   "outputs": [],
   "source": [
    "printfn \"%A\" ([1; 2; 3] @ [4; 5; 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!connect jupyter --kernel-name Rkernel --kernel-spec ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "print(append(c(1, 2, 3), c(4, 5, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "print(c(1, 2, 3) + c(4, 5, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "x <- 1:10\n",
    "y <- 2 * x + rnorm(10) # random numbers from a normal distribution with a mean of 10 and a standard deviation of 1\n",
    "\n",
    "# Create a dataframe\n",
    "df <- data.frame(x = x, y = y)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "# Perform linear regression\n",
    "model <- lm(y ~ x)\n",
    "\n",
    "# Display summary of the model\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "# Predict new values using the model\n",
    "new_x <- c(11, 12, 13)\n",
    "predictions <- predict(model, newdata = data.frame(x = new_x))\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "Rkernel"
    },
    "polyglot_notebook": {
     "kernelName": "Rkernel"
    }
   },
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "set.seed(123) # for reproducibility\n",
    "x <- 1:100\n",
    "y <- 2 * x + rnorm(100, mean = 0, sd = 20) # true relationship with added noise\n",
    "\n",
    "# Plot the data\n",
    "plot(x, y, main = \"Generated Data with Noise\")\n",
    "\n",
    "# Fit a linear regression model\n",
    "model <- lm(y ~ x)\n",
    "\n",
    "# Add the regression line to the plot\n",
    "abline(model, col = \"red\")\n",
    "\n",
    "# Display the summary of the model\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://education.rstudio.com/learn/beginner/\n",
    "    - https://posit.co/resources/videos/a-gentle-introduction-to-tidy-statistics-in-r\n",
    "    - https://towardsdatascience.com/a-gentle-guide-to-statistics-in-r-a1da223e08b7\n",
    "- https://moderndive.com/1-getting-started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://learn.microsoft.com/en-us/sql/machine-learning/r/sql-server-r-services\n",
    "    - https://learn.microsoft.com/en-us/sql/machine-learning/tutorials/quickstart-r-train-score-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node / Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "javascript"
    },
    "polyglot_notebook": {
     "kernelName": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "//console.log([] + []);\n",
    "console.log([] == []);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/Azure-Samples/ollama-javascript-playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GenAIScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://microsoft.github.io/genaiscript/getting-started/\n",
    "- https://microsoft.github.io/genaiscript/guides/phi3-with-ollama/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/llm-lossy-compression.jpg width=700><br>\n",
    "<img src=images/llm-creation-expansion.jpg width=700>\n",
    "\n",
    "__References__\n",
    "- https://www.getabstract.com/en/summary/chatgpt-is-a-blurry-jpeg-of-the-web/47101\n",
    "- https://www.youtube.com/watch?v=FYRp_blsxRI Is ChatGPT Lossy Compression Or Creative Expansion? | Yann Le Du | Medium Day 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/model-inference.png><br>\n",
    "<img src=images/model-function-calling.jpg width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "    - https://openai.com/index/function-calling-and-other-api-updates\n",
    "- Ollama\n",
    "    - https://ollama.com/library/mistral\n",
    "    - https://ollama.com/calebfahlgren/natural-functions    \n",
    "- Console Project Demo / Chat Bots / OpenAITools ðŸ‘ˆ \n",
    "- https://openai.com/index/introducing-structured-outputs-in-the-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/slm-tools-1.png><br>\n",
    "<img src=images/slm-tools-2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__References__\n",
    "- https://github.com/microsoft/Phi-3CookBook/blob/main/md/07.Labs/CsharpOllamaCodeSpaces/CsharpOllamaCodeSpaces.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/embeddings-2d.png width=800><br>\n",
    "<img src=images/embeddings-3d.png width=800>\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/vector-components.webp width=800><br>\n",
    "<img src=images/vector-dot-cross-products.png><br>\n",
    "<img src=images/cosine-similarity.png width=800>\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/ollama/ollama-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='llama2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "ollama.embeddings(\n",
    "  model='mxbai-embed-large',\n",
    "  prompt='A man is eating food',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "e1 = ollama.embeddings(\n",
    "  model='mxbai-embed-large',\n",
    "  prompt='A man is eating food',\n",
    "\n",
    ")['embedding'] # ollama.embeddings return a dictionary; embedding key is the vector\n",
    "e2 = ollama.embeddings(\n",
    "  model='mxbai-embed-large',\n",
    "  prompt='A man is eating pasta',\n",
    "\n",
    ")['embedding']\n",
    "e3 = ollama.embeddings(\n",
    "  model='mxbai-embed-large',\n",
    "  prompt='A man is riding a horse',\n",
    "  \n",
    ")['embedding']\n",
    "\n",
    "a = np.array(e1) # converting python array to numpy array\n",
    "b = np.array(e2)\n",
    "c = np.array(e3)\n",
    " \n",
    "# cosine similarities\n",
    "cosineAA = np.dot(a, a)/(norm(a) * norm(a))\n",
    "cosineAB = np.dot(a, b)/(norm(a) * norm(b))\n",
    "cosineBC = np.dot(b, c)/(norm(b) * norm(c))\n",
    "\n",
    "print(\"Cosine Similarities:\", cosineAA, cosineAB, cosineBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.pinecone.io/learn/vector-database\n",
    "- https://vector.dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.trychroma.com\n",
    "    - Batteries Included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# all-MiniLM-L6-v2\n",
    "\n",
    "# switch `create_collection` to `get_or_create_collection` to avoid creating a new collection every time\n",
    "collection = chroma_client.get_or_create_collection(name=\"my_collection\")\n",
    "\n",
    "# switch `add` to `upsert` to avoid adding the same documents every time\n",
    "collection.upsert(\n",
    "    documents=[\n",
    "        \"This is a document about pineapple\",\n",
    "        \"This is a document about oranges\"\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document about florida\"], # Chroma will embed this for you\n",
    "    n_results=2 # how many results to return\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can run the above code by saving in python file ðŸ‘ˆ\n",
    "- C:\\Users\\khurram\\.cache\\chroma\\onnx_models\n",
    "\n",
    "__References__\n",
    "- https://docs.trychroma.com/getting-started\n",
    "- https://docs.trychroma.com/guides\n",
    "- https://cookbook.chromadb.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuÃ±as and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "# store each document in a vector embedding database\n",
    "for i, d in enumerate(documents):\n",
    "  response = ollama.embeddings(model=\"mxbai-embed-large\", prompt=d)\n",
    "  embedding = response[\"embedding\"]\n",
    "  collection.add(\n",
    "    ids=[str(i)],\n",
    "    embeddings=[embedding],\n",
    "    documents=[d]\n",
    "  )\n",
    "\n",
    "  # an example prompt\n",
    "prompt = \"What animals are llamas related to?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"mxbai-embed-large\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=1\n",
    ")\n",
    "data = results['documents'][0][0]\n",
    "\n",
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "output = ollama.generate(\n",
    "  model=\"llama2\",\n",
    "  prompt=f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can run the above code by saving in python file ðŸ‘ˆ\n",
    "\n",
    "<img src=_clinic-slm-rag.png>\n",
    "\n",
    "__References__\n",
    "- https://ollama.com/blog/embedding-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://qdrant.tech/documentation/quickstart ðŸ‘ˆ\n",
    "- https://qdrant.tech/documentation/tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=4, distance=Distance.DOT),\n",
    ")\n",
    "\n",
    "operation_info = client.upsert(\n",
    "    collection_name=\"test_collection\",\n",
    "    wait=True,\n",
    "    points=[\n",
    "        PointStruct(id=1, vector=[0.05, 0.61, 0.76, 0.74], payload={\"city\": \"Berlin\"}),\n",
    "        PointStruct(id=2, vector=[0.19, 0.81, 0.75, 0.11], payload={\"city\": \"London\"}),\n",
    "        PointStruct(id=3, vector=[0.36, 0.55, 0.47, 0.94], payload={\"city\": \"Moscow\"}),\n",
    "        PointStruct(id=4, vector=[0.18, 0.01, 0.85, 0.80], payload={\"city\": \"New York\"}),\n",
    "        PointStruct(id=5, vector=[0.24, 0.18, 0.22, 0.44], payload={\"city\": \"Beijing\"}),\n",
    "        PointStruct(id=6, vector=[0.35, 0.08, 0.11, 0.44], payload={\"city\": \"Mumbai\"}),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(operation_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "search_result = client.query_points(\n",
    "    collection_name=\"test_collection\", query=[0.2, 0.1, 0.9, 0.7], limit=3\n",
    ").points\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pythonkernel"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "search_result = client.query_points(\n",
    "    collection_name=\"test_collection\",\n",
    "    query=[0.2, 0.1, 0.9, 0.7],\n",
    "    query_filter=Filter(\n",
    "        must=[FieldCondition(key=\"city\", match=MatchValue(value=\"London\"))]\n",
    "    ),\n",
    "    with_payload=True,\n",
    "    limit=3,\n",
    ").points\n",
    "\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://qdrant.tech/documentation/interfaces/web-ui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [],
      "languageName": "python",
      "name": "pythonkernel"
     },
     {
      "aliases": [],
      "languageName": "R",
      "name": "Rkernel"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
