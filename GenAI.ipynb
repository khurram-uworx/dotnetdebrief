{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AI and Generative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/suno.jpeg height=400><br>\n",
    "\n",
    "<img src=images/neither-a-nor-i.webp><br>\n",
    "\n",
    "<img src=images/ai-ml-dl.png height=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMs and SLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Size and Complexity\n",
    "    - More Parameters: Higher Capacity (**Maturity**)\n",
    "        - Generalization vs. Specialization\n",
    "        - Reasoning Depth\n",
    "        - Memory & Knowledge Storage\n",
    "        - Compute & Cost Implications\n",
    "    - Training Data (**Experience**)\n",
    "        - Diversity & Volume\n",
    "        - Domain-Specific vs. General Data\n",
    "        - Recency & Relevance\n",
    "    - Architecture (**Formal Structure**)\n",
    "        - Model Design\n",
    "        - Optimization Techniques\n",
    "        - Fine-Tuning & Adaptability\n",
    "    - Context Length | Tool Use | Fine Tuning \n",
    "- Resource Efficiency\n",
    "    - Quantization\n",
    "        - FP32, FP16/BF16, INT8, INT4, INT2\n",
    "        - Memory footprint\n",
    "        - Inference Speed/Energy\n",
    "        - Quality | Robustness | Stability\n",
    "- Knowledge Scope\n",
    "    - General Purpose vs. Domain Specific\n",
    "    - Textbooks are all you need\n",
    "    - Post Training Quantization (PTQ) vs. Quantization Aware Training (QAT)\n",
    "- Performance\n",
    "    - The Engine\n",
    "        - PyTorch | TensorFlow | ONNX Runtime | TensorRT | llama.cpp\n",
    "        - Same model / same hardware: 2-10x speed difference\n",
    "- Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Science of Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://en.wikipedia.org/wiki/Attention_Is_All_You_Need\n",
    "- https://cohere.com/llmu/what-are-transformer-models\n",
    "- https://www.youtube.com/watch?v=zjkBMFhNj_g [1hr Talk] Intro to Large Language Models\n",
    "\n",
    "<img src=images/transformer-architecture.webp width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Web APIs\n",
    "    - OpenAI | Azure OpenAI Service\n",
    "        - JSON based request/response\n",
    "        - Clear endpoints for chat completition, embeddings, audio and image generation\n",
    "    - Anthropic, Cohere and others vendor APIs\n",
    "    - Hugging Face and other model hosters Inference API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üêç Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#!connect jupyter --kernel-name pythonkernel --kernel-spec python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    "    api_key=\"ollama\" # ignored, but required by SDK\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"what is the area of Pakistan?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3.2:1b\"\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #Ô∏è‚É£ C#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: OpenAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using OpenAI;\n",
    "using OpenAI.Chat;\n",
    "using System.ClientModel;\n",
    "\n",
    "var client = new OpenAIClient(new ApiKeyCredential(\"ollama\"), new OpenAIClientOptions\n",
    "{\n",
    "    Endpoint = new Uri(\"http://localhost:11434/v1/\")\n",
    "});\n",
    "var chat = client.GetChatClient(\"llama3.2:1b\");\n",
    "var response = await chat.CompleteChatAsync([\n",
    "    new UserChatMessage(\"what is the area of Pakistan?\")\n",
    "]);\n",
    "\n",
    "response.Value.Content[0].Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/the-curly-languages.jpg height=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Model Runners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ollama\n",
    "    - Llama.cpp => CUDA | ROCm | Vulkan | Metal (Apple) | CPU (AVX/NEON)\n",
    "- AI Toolkit | Foundry\n",
    "    - Windows ML => Onnx Execution Providers\n",
    "    - GPU (CUDA, TensorRT, ROCm, QNN, OpenVINO) | NPU (OpenVINO) | CPU (oneDNN)\n",
    "- LM Studio\n",
    "    - Llama.cpp\n",
    "- Docker\n",
    "- vLLM\n",
    "    - PyTorch / Triton (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/dotnet/ai-samples/blob/main/src/mlnet-gen-ai üëà\n",
    "    - https://github.com/dotnet/ai-samples/blob/main/src/mlnet-gen-ai/LLaMA/LLaMA.csproj\n",
    "        - Tensorflow | Safetensors (Hugging Face)\n",
    "- https://github.com/dotnet/machinelearning/tree/main/src/Microsoft.ML.GenAI.Phi üëà\n",
    "- https://github.com/dotnet/machinelearning/tree/main/src/Microsoft.ML.GenAI.LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Videos üëà\n",
    "    - NPU | GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö° Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://openai.com/index/introducing-structured-outputs-in-the-api\n",
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "    - https://openai.com/index/function-calling-and-other-api-updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/model-function-calling.jpg width=800><br>\n",
    "\n",
    "<img src=images/model-inference.png><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gen AI / Chat Bots / OpenAITools üëà\n",
    "\n",
    "<img src=images/slm-tools-1.png><br>\n",
    "<img src=images/slm-tools-2.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¢ Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/embeddings-3d.png width=800>\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ollama\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "e1 = ollama.embeddings(\n",
    "  model='all-minilm',\n",
    "  prompt='A man is eating food',\n",
    "\n",
    ")['embedding'] # ollama.embeddings return a dictionary; embedding key is the vector\n",
    "e2 = ollama.embeddings(\n",
    "  model='all-minilm',\n",
    "  prompt='A man is eating pasta',\n",
    "\n",
    ")['embedding']\n",
    "e3 = ollama.embeddings(\n",
    "  model='all-minilm',\n",
    "  prompt='A man is riding a horse',\n",
    "  \n",
    ")['embedding']\n",
    "\n",
    "a = np.array(e1) # converting python array to numpy array\n",
    "b = np.array(e2)\n",
    "c = np.array(e3)\n",
    " \n",
    "# cosine similarities\n",
    "cosineAA = np.dot(a, a)/(norm(a) * norm(a))\n",
    "cosineAB = np.dot(a, b)/(norm(a) * norm(b))\n",
    "cosineBC = np.dot(b, c)/(norm(b) * norm(c))\n",
    "\n",
    "print(\"Cosine Similarities:\", cosineAA, cosineAB, cosineBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview / Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pythonkernel"
    }
   },
   "outputs": [],
   "source": [
    "import ollama\n",
    "import chromadb\n",
    "\n",
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicu√±as and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")\n",
    "\n",
    "# store each document in a vector embedding database\n",
    "for i, d in enumerate(documents):\n",
    "  response = ollama.embeddings(model=\"all-minilm\", prompt=d)\n",
    "  embedding = response[\"embedding\"]\n",
    "  collection.add(\n",
    "    ids=[str(i)],\n",
    "    embeddings=[embedding],\n",
    "    documents=[d]\n",
    "  )\n",
    "\n",
    "  # an example prompt\n",
    "prompt = \"What animals are llamas related to?\"\n",
    "\n",
    "# generate an embedding for the prompt and retrieve the most relevant doc\n",
    "response = ollama.embeddings(\n",
    "  prompt=prompt,\n",
    "  model=\"all-minilm\"\n",
    ")\n",
    "results = collection.query(\n",
    "  query_embeddings=[response[\"embedding\"]],\n",
    "  n_results=1\n",
    ")\n",
    "data = results['documents'][0][0]\n",
    "\n",
    "# generate a response combining the prompt and data we retrieved in step 2\n",
    "output = ollama.generate(\n",
    "  model=\"llama3.2:1b\",\n",
    "  prompt=f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    ")\n",
    "\n",
    "print(output['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üßÆ Qdrant and Pgvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://qdrant.tech/documentation/quickstart üëà\n",
    "- https://github.com/pgvector/pgvector\n",
    "\n",
    "To quickly have pgvector; use Docker and run it using one of the following command\n",
    "- docker run -e POSTGRES_PASSWORD=uworx -p 5432:5432 -d ankane/pgvector:latest\n",
    "- docker run -e POSTGRES_PASSWORD=uworx -p 5432:5432 -d pgvector/pgvector:pg17 üëà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "value"
    }
   },
   "outputs": [],
   "source": [
    "create extension vector;\n",
    "select * from pg_extension;\n",
    "\n",
    "create table Items (Id bigserial primary key, embedding vector(3));\n",
    "insert into Items (embedding) values ('[1, 2, 3]'), ('[4, 5, 6]');\n",
    "\n",
    "select * from Items order by embedding <-> '[3,1,2]' limit 5;\n",
    "/*\n",
    "    <-> is L2 distance, <#> is inner product, <=> is cosine distance\n",
    "*/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CAG: Cache Augmented Generation\n",
    "- GraphRAG\n",
    "- Struct RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/graph-rag-code-translation.png width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/rag.png width=800><br>\n",
    "<img src=images/rag-localdb.avif width=800><br>\n",
    "<img src=images/rag-use-cases.png width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AutoGen | **Semantic Kernel** > **Agent Framework**\n",
    "    - Microsoft Bot Framework\n",
    "    - Teams SDK | **M365 Agent SDK** | Copilot SDK\n",
    "- LangChain\n",
    "- LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .NET üíñ AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Microsoft.Extensions.AI\n",
    "    - IChatClient, IEmbeddingGenertor and IImageGenerator‚Äã\n",
    "    - OpenAI, Anthropic, Gemini and others‚Äã\n",
    "    - ML.NET (Onnx) and LlamaSharp offers IChatClient‚Äã\n",
    "    - OllamaSharp for local/on-prem inference (Foundry Local)‚Äã\n",
    "    - Prompt/Response Interception, Rate Limiting, Retries‚Äã\n",
    "    - Telemetry, Cached Client, Evaluations‚Äã\n",
    "    - src / Chat Bots / AIExtensionTools üëà\n",
    "    - **Resources**\n",
    "        - https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-ai-preview\n",
    "        - https://devblogs.microsoft.com/semantic-kernel/microsoft-extensions-ai-simplifying-ai-integration-for-net-partners\n",
    "        - https://learn.microsoft.com/en-us/dotnet/ai/ai-extensions üëà\n",
    "        - https://github.com/dotnet/ai-samples/tree/main/src/microsoft-extensions-ai üëà\n",
    "        - https://devblogs.microsoft.com/dotnet/e-shop-infused-with-ai-comprehensive-intelligent-dotnet-app-sample üëà\n",
    "- Microsoft.Extensions.VectorData\n",
    "    - Azure AI Search, Cosmos DB\n",
    "    - In Memory, Volatile (In Memory)\n",
    "    - Elasticsearch, MongoDB, Pinecone, Qdrant, Redis, SQLLite, Weaviate\n",
    "    - Chroma, Milvis, Postgres, Sql Server coming soon\n",
    "    - **Resources**\n",
    "        - https://devblogs.microsoft.com/dotnet/introducing-pinecone-dotnet-sdk üëà\n",
    "        - https://devblogs.microsoft.com/dotnet/vector-data-qdrant-ai-search-dotnet üëà\n",
    "        - https://devblogs.microsoft.com/dotnet/introducing-microsoft-extensions-vector-data\n",
    "        - https://devblogs.microsoft.com/semantic-kernel/microsoft-extensions-vectordata-abstractions-now-available\n",
    "        - https://learn.microsoft.com/en-us/semantic-kernel/concepts/vector-store-connectors/out-of-the-box-connectors\n",
    "- Microsoft Agent Framework\n",
    "    - Semantic Kernel\n",
    "    - AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/sk-tool-km.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://devblogs.microsoft.com/dotnet/e-shop-infused-with-ai-comprehensive-intelligent-dotnet-app-sample\n",
    "- https://devblogs.microsoft.com/dotnet/local-ai-models-with-dotnet-aspire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://learn.microsoft.com/en-us/dotnet/ai/conceptual/data-ingestion\n",
    "    - https://devblogs.microsoft.com/dotnet/introducing-data-ingestion-building-blocks-preview\n",
    "- https://learn.microsoft.com/en-us/dotnet/ai/quickstarts/ai-templates\n",
    "    - src / Ai Chat Web üëà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Attention is all you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Year** | **Milestone / Developer Impact**                                                  |\n",
    "| -------- | --------------------------------------------------------------------------------- |\n",
    "| **2017** | Attention Is All You Need (Transformer)                                           |\n",
    "| **2018** | BERT; GPT-1                                                                       |\n",
    "| **2019** | GPT-2                                                                             |\n",
    "| **2020** | GPT-3                                                                             |\n",
    "| **2022** | ChatGPT launch                                                                    |\n",
    "| **2023** | Function Calling in OpenAI API                                                    |\n",
    "| **2024** | GPT-4o multimodal; Structured Outputs API                                         |\n",
    "| **2025** | Responses API; MCP standard; ChatGPT Agents; GPT-4.1 / GPT-4.5; GPT-5.1 / GPT-5.2 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/sell-me-this-pen.jpg height=500>\n",
    "<img src=images/ai-startup.webp height=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/this-is-not-enough.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Context Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.anthropic.com/news/model-context-protocol\n",
    "- https://github.com/modelcontextprotocol\n",
    "    - https://github.com/modelcontextprotocol/csharp-sdk\n",
    "    - https://github.com/modelcontextprotocol/servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/mcp2.png height=400><br>\n",
    "<img src=images/mcp.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/agents.png width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://devblogs.microsoft.com/semantic-kernel/customer-case-story-creating-a-semantic-kernel-agent-for-automated-github-code-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.anthropic.com/news/3-5-models-and-computer-use\n",
    "- src / ComputerUse üëà\n",
    "\n",
    "<img src=images/computer-use-chat-loop.png width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- src / ChatBots / Agents.cs üëà\n",
    "- https://github.com/microsoft/Agent-Framework-Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLI Agents**\n",
    "- Copilot\n",
    "    - https://www.youtube.com/watch?v=UMz8aQ4lOtE Demo: Using GitHub Copilot CLI and yolo mode\n",
    "        - WorkIQ üëà\n",
    "    - https://github.blog/ai-and-ml/github-copilot/power-agentic-workflows-in-your-terminal-with-github-copilot-cli\n",
    "    - https://github.blog/news-insights/company-news/build-an-agent-into-any-app-with-the-github-copilot-sdk\n",
    "- Rovo\n",
    "    - Pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/ai-protocol-stack.avif>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=4CrxcdNbRFY\n",
    "    - 45mins,  ASP.NET Community Standup - Build agentic UI with AG-UI and Blazor\n",
    "    - https://learn.microsoft.com/en-us/agent-framework/overview/agent-framework-overview\n",
    "    - https://learn.microsoft.com/en-us/agent-framework/integrations/ag-ui\n",
    "    - https://docs.copilotkit.ai/microsoft-agent-framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=images/gen-ai.png>\n",
    "\n",
    "- https://openai.com/index/introducing-apps-in-chatgpt üöÄ\n",
    "- https://blog.modelcontextprotocol.io/posts/2026-01-26-mcp-apps üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "polyglot-notebook",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     },
     {
      "aliases": [],
      "languageName": "python",
      "name": "pythonkernel"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
